{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets huggingface_hub fsspec"
      ],
      "metadata": {
        "id": "t12I28a1ErFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "dataset = load_dataset(\"natural_questions\", split=\"train\", streaming=True)\n",
        "sample_dataset = []\n",
        "for i, item in enumerate(dataset):\n",
        "    if i >= 1500:\n",
        "        break\n",
        "    sample_dataset.append(item)\n",
        "\n",
        "queries = [item['question'] for item in sample_dataset]"
      ],
      "metadata": {
        "id": "qPwyNmx7hOAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_for_query_analysis(query):\n",
        "    prompt = f\"\"\"\n",
        "You are an assistant that performs step-by-step analysis of user queries.\n",
        "\n",
        "**Instructions for Query Analysis:**\n",
        "When given a query, please **understand the query intents**, and classify the query as either **[Local]** or **[Global]**.\n",
        "- **[Global]**: The query requires a broad or vague range of knowledge (e.g., summary or open-ended questions), and may require a comprehensive understanding of the document.\n",
        "- **[Local]**: The query has a clear and fixed answer with a narrow scope of knowledge (e.g., factual questions), and only a small amount of text fragments are needed to answer.\n",
        "\n",
        "**Output Format:**\n",
        "Please present the results in JSON format with the following keys:\n",
        "**query_type**: [Local] or [Global]\n",
        "\n",
        "**Demonstration**\n",
        "Query: What is the summary of the movie \"Inception\"?\n",
        "Results: {{\"query_type\": \"[Global]\"}}\n",
        "Query: Who directed the movie \"Inception\"?\n",
        "Results: {{\"query_type\": \"[Local]\"}}\n",
        "\n",
        "Query: {query}\n",
        "Results:\n",
        "\"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "yMfKaqedEf0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_query_type_from_llm(query):\n",
        "    \"\"\"\n",
        "    使用 API 配置调用 LLM 并获取查询类型。\n",
        "    \"\"\"\n",
        "    prompt = create_prompt_for_query_analysis(query)\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"qwen3-30b-a3b\",\n",
        "            messages=[\n",
        "                {'role': 'user', 'content': prompt}\n",
        "            ],\n",
        "            temperature=0.2, # 使用低温度确保结果的确定性\n",
        "            extra_body={\"enable_thinking\": False}\n",
        "\n",
        "        )\n",
        "\n",
        "        # 获取模型返回的内容\n",
        "        response_content = completion.choices[0].message.content\n",
        "\n",
        "        # 尝试解析JSON\n",
        "        result_json = json.loads(response_content)\n",
        "        query_type = result_json.get(\"query_type\")\n",
        "\n",
        "        if query_type not in [\"[Local]\", \"[Global]\"]:\n",
        "             print(f\"Warning: Invalid query_type '{query_type}' for query: '{query}'\")\n",
        "             return None\n",
        "\n",
        "        return query_type\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Failed to decode JSON from response for query '{query}'. Response: '{response_content}'\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing query '{query}': {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ID8JyBxDEgzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. 主循环和数据保存 ---\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import json\n",
        "training_data = []\n",
        "print(\"Starting data generation...\")\n",
        "\n",
        "client = OpenAI(\n",
        "        api_key=\"sk-5b66681c866645db837eb74acc66637e\",\n",
        "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
        "    )\n",
        "\n",
        "\n",
        "for query in tqdm(queries, desc=\"Generating Query Types\"):\n",
        "    query_type = get_query_type_from_llm(query)\n",
        "    if query_type:\n",
        "        training_data.append({\"query\": query, \"query_type\": query_type})\n",
        "\n",
        "print(f\"\\nSuccessfully generated data for {len(training_data)} queries.\")\n",
        "\n",
        "# 保存为JSON Lines文件\n",
        "output_filename = \"step1_data.jsonl\"\n",
        "print(f\"Saving data to '{output_filename}'...\")\n",
        "try:\n",
        "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for item in training_data:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "    print(\"Data generation complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving data to file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY4YmS41EjS-",
        "outputId": "e096fbbd-4803-4e9c-e555-4ce4cfc71844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data generation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Query Types: 100%|██████████| 1500/1500 [24:26<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successfully generated data for 1500 queries.\n",
            "Saving data to 'query_analysis_data.jsonl'...\n",
            "Data generation complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBz59CGdGNBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}